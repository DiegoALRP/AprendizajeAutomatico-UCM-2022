{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caf3c22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error obtenido de:  3.5720266194953574\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import scipy.optimize as opt\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def sigmoide(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "#Función para el coste\n",
    "def coste(theta, X, y, landa, m):\n",
    "    h = np.dot(X, theta)\n",
    "\n",
    "    return ((1 / (2 * m)) * (np.sum(np.square(h - y)))) + ((landa / (2 * m)) * np.sum(np.square(theta[1:len(theta)])))\n",
    "    \n",
    "#Función para calculo de gradiente\n",
    "def gradiente(theta, XX, Y, landa, m): \n",
    "    h = np.dot(XX, theta)\n",
    "\n",
    "    grad = (1 / m) * np.dot(XX.T, h - Y)+((landa/m) * theta)\n",
    "    return grad\n",
    "\n",
    "def coste_y_gradiente(theta, X, Y, landa, m):\n",
    "\n",
    "    theta = theta.reshape(-1, Y.shape[1])\n",
    "\n",
    "    cost = coste(theta, X, Y, landa, m) \n",
    "    grad = gradiente(theta, X, Y, landa, m)\n",
    "    \n",
    "    grad[0] = (1 / m) * np.dot(X.T, np.dot(X, theta) - Y)[0]\n",
    "\n",
    "    return (cost, grad.flatten())\n",
    "\n",
    "def calcOptTheta(X, Y, landa):\n",
    "    theta = np.zeros((X.shape[1], 1))\n",
    "    \n",
    "    def costFunction(theta):\n",
    "        return coste_y_gradiente(theta, X, Y, landa, len(X))\n",
    "\n",
    "    result = minimize(fun=costFunction, x0=theta, method='CG', jac=True, options={'maxiter':200})\n",
    "    \n",
    "    return result.x\n",
    "\n",
    "def curva_aprendizaje(X, y, landa, Xval, yval):\n",
    "\n",
    "    err1 = np.zeros((len(landa)))\n",
    "    err2 = np.zeros((len(landa)))\n",
    "\n",
    "    i = 0\n",
    "    while (i < len(landa)):\n",
    "        thetas = calcOptTheta(X, y, landa[i])\n",
    "\n",
    "        #IMPORTANTE que landa tiene que ser 0 aquí \n",
    "        err1[i] = coste_y_gradiente(thetas, X, y, 0, len(X))[0]\n",
    "        err2[i] = coste_y_gradiente(thetas, Xval, yval, 0, len(Xval))[0]\n",
    "        i += 1   \n",
    "\n",
    "    return err1, err2    \n",
    "\n",
    "def pinta_Curva_Aprendizaje(landaV, err1, err2):\n",
    "    b = err1\n",
    "    plt.plot(landaV, b, c=\"blue\", label=\"Train\")\n",
    "\n",
    "    d = err2\n",
    "    plt.plot(landaV, d, c=\"orange\", label=\"Cross Validation\")\n",
    "\n",
    "def normaliza_Matriz(X):\n",
    "    mu = np.mean(X, axis=0)\n",
    "    X_norm = X - mu\n",
    "    \n",
    "    sigma = np.std(X_norm, axis=0)\n",
    "    X_norm = X_norm / sigma\n",
    "    \n",
    "    return X_norm, mu, sigma\n",
    "\n",
    "def transforma_entrada(X, p):\n",
    "    nX = X\n",
    "    for i in range(1, p):\n",
    "        nX = np.column_stack((nX, np.power(X, i+1)))   \n",
    "\n",
    "    return nX\n",
    "\n",
    "def main():\n",
    "    data = loadmat(\"ex5data1.mat\")\n",
    "\n",
    "    X = data[\"X\"]\n",
    "    y = data[\"y\"]\n",
    "    Xval = data[\"Xval\"]\n",
    "    yval = data[\"yval\"]\n",
    "    Xtest = data[\"Xtest\"]\n",
    "    ytest = data[\"ytest\"]\n",
    "\n",
    "    landas = np.array([0, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10])\n",
    "    p = 8\n",
    "\n",
    "    nuevaentrada = transforma_entrada(X, p)\n",
    "    nuevaentrada, mu, sigma = normaliza_Matriz(nuevaentrada)\n",
    "    nuevaentrada = np.insert(nuevaentrada, 0, 1, axis=1)  \n",
    "    \n",
    "    neuvaEntradaValidacion = transforma_entrada(Xval, p)\n",
    "    neuvaEntradaValidacion = neuvaEntradaValidacion - mu\n",
    "    neuvaEntradaValidacion = neuvaEntradaValidacion / sigma\n",
    "    neuvaEntradaValidacion = np.insert(neuvaEntradaValidacion, 0, 1, axis=1)\n",
    "\n",
    "    err1, err2 = curva_aprendizaje(nuevaentrada, y, landas, neuvaEntradaValidacion, yval)  \n",
    "\n",
    "    pinta_Curva_Aprendizaje(landas, err1, err2)\n",
    "    \n",
    "\n",
    "    #De todo esto anterior, sacamos como conclusión que el valor óptimo para lambda\n",
    "    # es 3, por lo que ahora, con los ejemplos de test comprobaremos el error obtenido\n",
    "    landa = 3\n",
    "    \n",
    "    neuvaEntradaTest = transforma_entrada(Xtest, p)\n",
    "    neuvaEntradaTest = neuvaEntradaTest - mu\n",
    "    neuvaEntradaTest = neuvaEntradaTest / sigma\n",
    "    neuvaEntradaTest = np.insert(neuvaEntradaTest, 0, 1, axis=1)\n",
    "\n",
    "    optTheta = calcOptTheta(nuevaentrada, y, landa)\n",
    "\n",
    "    #Lambda siempre = 0\n",
    "    error_test = coste_y_gradiente(optTheta, neuvaEntradaTest, ytest, 0, len(neuvaEntradaTest))[0] #[0] para que lo que devuelva sea el coste\n",
    "\n",
    "    print(\"Error obtenido de: \", error_test)\n",
    "   \n",
    "    plt.show()\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "151239b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.core.fromnumeric import transpose\n",
    "from scipy.io import loadmat\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def gradiente(Theta,X,Y):\n",
    "\tm = np.shape(X)[0]\n",
    "\tH = np.dot(X,Theta)\n",
    "\treturn np.dot(H-Y.T,X)/m\n",
    "\n",
    "def gradiente_reg_1(theta, X, Y, landa):\n",
    "    theta = theta.reshape((theta.shape[0], 1))\n",
    "    m = X.shape[0]\n",
    "    H = np.matmul(X, theta)\n",
    "    grad = (X.T.dot(H-Y)/(m)) + ((landa)/m)*theta\n",
    "    return grad\n",
    "\n",
    "def gradiente_reg_2(theta, X, Y, landa):\n",
    "    m = np.shape(X)[0]\n",
    "    grad = gradiente(theta,X,Y)\n",
    "    grad_0 = grad[0]\n",
    "    j = grad + (landa/(m))*theta\n",
    "    j[0] = grad_0\n",
    "    return j\n",
    "\n",
    "\n",
    "def coste_reg(theta, X, Y, landa):\n",
    "    m = np.shape(X)[0]\n",
    "    H = np.dot(X,theta)\n",
    "    return (np.sum((H-Y.T)**2))/(2*m) + (landa/(2*m))*np.sum(theta[1:] **2)\n",
    "\n",
    "\n",
    "def calcula_coste_gradiente_reg_1(theta, X, Y, landa):\n",
    "    return coste_reg(theta, X, Y, landa), gradiente_reg_1(theta, X, Y, landa)\n",
    "\n",
    "\n",
    "def calcula_coste_gradiente_reg_2(theta, X, Y, landa):\n",
    "    return coste_reg(theta, X, Y, landa), gradiente_reg_2(theta, X, Y, landa)\n",
    "\n",
    "\n",
    "def normaliza(matriz):\n",
    "    #xi = (xi - ui) / si\n",
    "    #ui = media ; si = desviación típica\n",
    "    matriz_normal = np.empty_like(matriz)\n",
    "\n",
    "    u = np.mean(matriz, axis=0)\n",
    "    s = np.std(matriz, axis=0)\n",
    "    # print('Media: ' + str(u))\n",
    "    # print('Desv: ' + str(s))\n",
    "\n",
    "    matriz_normal = (matriz - u) / s\n",
    "\n",
    "    return [matriz_normal, u, s]\n",
    "\n",
    "def nuevos_datos(X, p) :\n",
    "    mat = np.zeros([np.shape(X)[0], p])\n",
    "\n",
    "    for i in range(1, p+1) :\n",
    "        mat[:, i-1] = (X**i).ravel()\n",
    "    \n",
    "    #print(\"nuevos\", mat)\n",
    "    return mat\n",
    "\n",
    "\n",
    "def apartado1(X, y):\n",
    "    #m = np.shape(X)[0]\n",
    "\n",
    "    auxX = np.insert(X, 0, 1, axis=1)\n",
    "\n",
    "    theta = np.array([[1], [1]])\n",
    "    landa = 0\n",
    "\n",
    "    #coste = coste_reg(theta, auxX, y, landa)\n",
    "    #g = gradiente_reg_1(theta, auxX, y, landa)\n",
    "\n",
    "    result = minimize(calcula_coste_gradiente_reg_1, theta,\n",
    "                      args=(auxX, y, landa), jac=True, method='TNC')\n",
    "\n",
    "    # Pintamos grafica\n",
    "    plt.figure()\n",
    "    # Pintamos x\n",
    "    plt.plot(X, y, \"x\", color='red')\n",
    "\n",
    "    min_x = min(X)\n",
    "    max_x = max(X)\n",
    "    min_y = result.x[0] + result.x[1]*min_x\n",
    "    max_y = result.x[0] + result.x[1]*max_x\n",
    "\n",
    "    # Pintamos recta\n",
    "    plt.plot([min_x, max_x], [min_y, max_y], color='blue', linewidth=2)\n",
    "    # Guardamos imagen\n",
    "    plt.savefig(\"regresionLineal.png\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def apartado2(X, y, Xval, yval, landa):\n",
    "    m = np.shape(X)[0]\n",
    "    mValidacion = np.shape(Xval)[0]\n",
    "    Xval = np.hstack([np.ones([mValidacion,1]),Xval])\n",
    "    \n",
    "    eValidation = np.zeros([m])\n",
    "    eTraning = np.zeros([m])\n",
    "    \n",
    "    for i in range(1,m+1):\n",
    "        theta = np.zeros(np.shape(X)[1])\n",
    "        result = minimize(calcula_coste_gradiente_reg_2, theta, args = (X[0:i], y[0:i,0], landa), jac = True, method = 'TNC')\n",
    "        eTraning[i-1] = coste_reg(result.x, X[0:i], y[0:i], landa)\n",
    "        eValidation[i-1] = coste_reg(result.x, Xval, yval, landa)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(np.linspace(0,11,12,dtype=int), eTraning, label='Train')\n",
    "    plt.plot(np.linspace(0,11,12,dtype=int), eValidation, label='Cross Validation')\n",
    "    plt.legend()\n",
    "    plt.title('Learning curve for linear regression')\n",
    "    plt.xlabel('Number of training examples')\n",
    "    plt.ylabel('Error')    \n",
    "    plt.savefig(\"curvasAprendizaje.png\")\n",
    "    plt.show()\n",
    "    # Guardamos imagen\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def apartado3(X, p, landa) :\n",
    "    mat = nuevos_datos(X, p)\n",
    "    u = np.zeros([p])\n",
    "    s = np.zeros([p])\n",
    "    mat, u, s = normaliza(mat)\n",
    "    \n",
    "\n",
    "    mat = np.hstack([np.ones([np.shape(mat)[0],1]),mat])\n",
    "    \n",
    "    print(\"map:\", mat)\n",
    "    \n",
    "\n",
    "    theta = np.zeros(np.shape(mat[1]))\n",
    "    \n",
    "    print(\"theta\", theta)\n",
    "\n",
    "    result = minimize(calcula_coste_gradiente_reg_2, theta,\n",
    "                      args=(mat, y, landa), jac=True, method='TNC')\n",
    "    \n",
    "    print(\"Result\", result)\n",
    "\n",
    "    # Pintamos grafica\n",
    "    plt.figure()\n",
    "    # Pintamos x\n",
    "    plt.plot(X, y, \"x\", color='red')\n",
    "    # Pintamos la linea\n",
    "    lineX = np.arange(np.min(X),np.max(X),0.05)\n",
    "    aux_x = (nuevos_datos(lineX, p)-u) / s\n",
    "    print(\"aux\", aux_x)\n",
    "    lineY = np.hstack([np.ones([len(aux_x),1]),aux_x]).dot(result.x)\n",
    "    plt.plot(lineX, lineY, '-', c = 'blue')\n",
    "    #plt.savefig(\"regPolinomial.png\")\n",
    "    plt.show()\n",
    "    # Guardamos imagen\n",
    "    plt.close()\n",
    "\n",
    "def apartado3_2(X,p, xval, landa):\n",
    "    mat, u, s = normaliza(nuevos_datos(X, p))\n",
    "    mat = np.hstack([np.ones([np.shape(mat)[0],1]),mat])\n",
    "\n",
    "    matXval =  (nuevos_datos(xval,p) - u  )/s\n",
    "    print(\"newX\", mat)\n",
    "    print(\"newXval\", matXval)\n",
    "    apartado2(mat, y, matXval, yval, landa)\n",
    "\n",
    "def apartado4_1(X, xVal, y, yVal,p ):\n",
    "    lambdas = np.array([0, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10])\n",
    "    \n",
    "    mat, u , s = normaliza(nuevos_datos(X,p))\n",
    "    matXval, uXval, sXval =  normaliza(nuevos_datos(xVal, p))\n",
    "\n",
    "    mat = np.hstack([np.ones([np.shape(mat)[0],1]),mat])\n",
    "    matXval = np.hstack([np.ones([np.shape(matXval)[0],1]),matXval])\n",
    "\n",
    "    eTraining = np.zeros((len(lambdas),1))\n",
    "    print(eTraining)\n",
    "    eValidation = np.zeros((len(lambdas),1))\n",
    "\n",
    "    for i in range(len(lambdas)):\n",
    "        theta = np.zeros(np.shape(mat)[1])\n",
    "        result = minimize(calcula_coste_gradiente_reg_2, theta, args = (mat, y, lambdas[i]), jac = True, method = 'TNC')\n",
    "        eTraining[i] = coste_reg(result.x,mat,y,0)\n",
    "        eValidation[i] = coste_reg(result.x,matXval,yVal,0)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(lambdas,eTraining,label=\"Entrenamiento\")\n",
    "    plt.plot(lambdas,eValidation,label=\"Validacion\")\n",
    "    plt.savefig(\"PruebasLambdas.png\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def apartado4_2( X, XTest,  y, yTest, p, landa):\n",
    "    mat, u , s = normaliza(nuevos_datos(X,p))\n",
    "    mat = np.hstack([np.ones([np.shape(mat)[0],1]),mat])\n",
    "\n",
    "    theta = np.zeros(np.shape(mat[1]))\n",
    "\n",
    "    result = minimize(calcula_coste_gradiente_reg_2, theta, args = (mat, y, landa ), jac = True, method = 'TNC')\n",
    "    \n",
    "    matTest = nuevos_datos(XTest,p)\n",
    "    matTest = ((matTest - u)/s)\n",
    "    matTest = np.hstack([np.ones([np.shape(matTest)[0],1]),matTest])\n",
    "    \n",
    "    error = coste_reg(result.x, matTest, yTest, 0)\n",
    "    print(\"Error para lambda = 3: \"  + str(error))\n",
    "\n",
    "data = loadmat('ex5data1.mat')\n",
    "\n",
    "y = data['y']\n",
    "X = data['X']\n",
    "m = np.shape(X)[0]\n",
    "auxX = np.hstack([np.ones([m,1]),X])\n",
    "\n",
    "Xval = data['Xval']\n",
    "yval = data['yval']\n",
    "\n",
    "#apartado1(X,y)\n",
    "#apartado2(auxX, y, Xval, yval, 0)\n",
    "#apartado3(X, 8, 0)\n",
    "\n",
    "#apartado3_2(X,8,Xval, 0)\n",
    "apartado4_1(X,Xval, y, yval, 8)\n",
    "\n",
    "#apartado4_2(X,data['Xtest'], y, data['ytest'], 8, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0acdb77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta [1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "X [[ 1.00000000e+00 -3.78243704e-01 -7.88662325e-01  1.90328720e-01\n",
      "  -7.37591303e-01  3.20251970e-01 -6.17151602e-01  3.59835014e-01\n",
      "  -5.31091256e-01]\n",
      " [ 1.00000000e+00 -8.38920100e-01  1.31420204e-03 -2.58961742e-01\n",
      "  -3.41564822e-01  9.75492734e-02 -4.55196644e-01  2.66773432e-01\n",
      "  -4.68873807e-01]\n",
      " [ 1.00000000e+00  1.43871736e+00  6.10831582e-01  1.30534069e+00\n",
      "   2.56220001e-01  1.02186338e+00 -1.26962121e-02  7.90210009e-01\n",
      "  -1.77926980e-01]\n",
      " [ 1.00000000e+00  1.48412330e+00  7.38068463e-01  1.42031240e+00\n",
      "   4.13121830e-01  1.15534830e+00  1.31223708e-01  9.10700224e-01\n",
      "  -6.22895388e-02]\n",
      " [ 1.00000000e+00 -1.49791929e+00  1.93643966e+00 -2.12774745e+00\n",
      "   2.43510061e+00 -2.51876748e+00  2.71792174e+00 -2.76331690e+00\n",
      "   2.88908182e+00]\n",
      " [ 1.00000000e+00 -1.34409278e-01 -1.01936614e+00  2.62563148e-01\n",
      "  -7.72577738e-01  3.31046537e-01 -6.21453712e-01  3.61188658e-01\n",
      "  -5.31586524e-01]\n",
      " [ 1.00000000e+00  7.10844248e-01 -8.14713668e-01  3.55803314e-01\n",
      "  -7.43368461e-01  3.41027665e-01 -6.18104683e-01  3.62252117e-01\n",
      "  -5.31229003e-01]\n",
      " [ 1.00000000e+00 -1.03249041e+00  4.71428060e-01 -6.28018432e-01\n",
      "   9.70487696e-02 -2.28187552e-01 -1.47905228e-01  4.11556057e-02\n",
      "  -2.78551428e-01]\n",
      " [ 1.00000000e+00  2.25683763e-01 -1.12279332e+00  2.78115330e-01\n",
      "  -7.76423647e-01  3.31682056e-01 -6.21592224e-01  3.61212770e-01\n",
      "  -5.31591435e-01]\n",
      " [ 1.00000000e+00 -1.36981778e+00  1.48607235e+00 -1.61695958e+00\n",
      "   1.55980151e+00 -1.58331392e+00  1.45040261e+00 -1.42914967e+00\n",
      "   1.27857621e+00]\n",
      " [ 1.00000000e+00  4.21731046e-01 -1.06014377e+00  2.85534542e-01\n",
      "  -7.74969228e-01  3.31870677e-01 -6.21559967e-01  3.61217175e-01\n",
      "  -5.31590732e-01]\n",
      " [ 1.00000000e+00  9.70700848e-01 -4.38475085e-01  5.33689054e-01\n",
      "  -6.14797521e-01  3.99629101e-01 -5.83887796e-01  3.77921571e-01\n",
      "  -5.22927330e-01]]\n",
      "Y [ 2.13431051  1.17325668 34.35910918 36.83795516  2.80896507  2.12107248\n",
      " 14.71026831  2.61418439  3.74017167  3.73169131  7.62765885 22.7524283 ]\n",
      "Lambda 3\n",
      "Y [ 2.13431051  1.17325668 34.35910918 36.83795516  2.80896507  2.12107248\n",
      " 14.71026831  2.61418439  3.74017167  3.73169131  7.62765885 22.7524283 ]\n",
      "[-10.21758933  -8.77356739  -0.18668793  -7.39073489   1.38604641\n",
      "  -6.07800778   2.36358063  -5.09594533   2.93928726]\n"
     ]
    }
   ],
   "source": [
    "import scipy.optimize\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_decisionboundary(X, Y, Theta, poly):\n",
    "    x1_min, x1_max = X[:, 0].min(), X[:, 0].max()\n",
    "    x2_min, x2_max = X[:, 1].min(), X[:, 1].max()\n",
    "    xx1, xx2 = np.meshgrid(np.linspace(x1_min, x1_max),\n",
    "                           np.linspace(x2_min, x2_max))\n",
    "\n",
    "    h = coste_lineal(poly.fit_transform(np.c_[xx1.ravel(),\n",
    "                                              xx2.ravel()]).dot(Theta))\n",
    "    h = h.reshape(xx1.shape)\n",
    "\n",
    "    plt.contour(xx1, xx2, h, [0.5], linewidths=1, colors='g')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def h(x, theta):\n",
    "    return theta[0] + theta[1] * x\n",
    "\n",
    "\n",
    "def plot_line(X, Y):\n",
    "    plt.plot(X, Y)\n",
    "\n",
    "\n",
    "def plot_regression(X, Y, theta):\n",
    "    min_x = np.min(X)\n",
    "    max_x = np.max(X)\n",
    "    min_y = h(min_x, theta)\n",
    "    max_y = h(max_x, theta)\n",
    "    plt.plot(X, Y, \"x\")\n",
    "    plt.plot([min_x, max_x], [min_y, max_y])\n",
    "    # plt.savefig(\"apartado1_line.png\")\n",
    "\n",
    "\n",
    "def coste_regularizado(Theta, X, Y, lamb):\n",
    "    m = X.shape[0]\n",
    "    reg = (lamb / (2 * m)) * np.sum(Theta[1:] ** 2)\n",
    "    return coste_lineal(Theta, X, Y) + reg\n",
    "\n",
    "\n",
    "def coste_lineal(Theta, X, Y):\n",
    "    m = X.shape[0]\n",
    "    H = np.dot(X, np.transpose(Theta))\n",
    "    sigma = np.sum((H - Y) ** 2)\n",
    "    return sigma / (2 * m)\n",
    "\n",
    "\n",
    "def gradiente(Theta, X, Y):\n",
    "    m = np.shape(X)[0]\n",
    "    H = np.dot(X, Theta)\n",
    "    print(\"Y\", Y)\n",
    "    a = np.matmul(np.transpose(X), H - Y)\n",
    "    return a / m\n",
    "\n",
    "\n",
    "def gradiente_regularizado(Theta, X, Y, lamb):\n",
    "    print(\"Theta\", Theta.shape)\n",
    "    print(\"X\", X.shape)\n",
    "    print(\"Y\", Y.shape)\n",
    "    grad = gradiente(Theta, X, Y)\n",
    "    g_0 = grad[0]\n",
    "    regularizador = (lamb / np.shape(X)[0]) * Theta\n",
    "    grad = grad + regularizador\n",
    "    grad[0] = g_0\n",
    "    return grad\n",
    "\n",
    "\n",
    "def minimize_this_pls(Theta, X, Y, lamb):\n",
    "    return coste_regularizado(Theta, X, Y, lamb), gradiente_regularizado(Theta, X, Y, lamb)\n",
    "\n",
    "\n",
    "def normaliza_matriz(x):\n",
    "    mu = np.mean(x, axis=0)  # Media de cada columna\n",
    "    sigma = np.std(x, axis=0)  # Desviacion estandar por columnas, no confundir con la querida std de c++\n",
    "\n",
    "    return (x - mu) / sigma, mu, sigma\n",
    "\n",
    "\n",
    "def polinomiza_atributos(X, p):\n",
    "    Pol = X\n",
    "    for i in range(2, p + 1):\n",
    "        Pol = np.hstack([Pol, X ** i])\n",
    "\n",
    "    return Pol\n",
    "\n",
    "\n",
    "def load_data(filename='ex5data1.mat'):\n",
    "    data = loadmat(filename)\n",
    "    X = data['X']\n",
    "    Y = data['y']\n",
    "    Y = Y[:, -1]\n",
    "    X_val = data['Xval']\n",
    "    Y_val = data['yval']\n",
    "    Y_val = Y_val[:, -1]\n",
    "    X_test = data['Xtest']\n",
    "    Y_test = data['ytest']\n",
    "    Y_test = Y_test[:, -1]\n",
    "    return X, Y, X_val, Y_val, X_test, Y_test\n",
    "\n",
    "\n",
    "def learning_curves():\n",
    "    X, Y, X_val, Y_val, X_test, Y_test = load_data()\n",
    "\n",
    "    X = np.hstack([np.ones([X.shape[0], 1]), X])\n",
    "    X_val = np.hstack([np.ones([X_val.shape[0], 1]), X_val])\n",
    "    m = X.shape[0]\n",
    "\n",
    "    Errors = np.empty((m, 2))\n",
    "    sliceSize = np.arange(1, m)\n",
    "\n",
    "    for i in sliceSize:\n",
    "        Theta = np.array([1, 1])\n",
    "        res = scipy.optimize.minimize(minimize_this_pls, Theta, args=(X[0:i], Y[0:i], 0),\n",
    "                                      jac=True, method='TNC')\n",
    "        err = coste_lineal(res.x, X[0:i], Y[0:i])\n",
    "        errVal = coste_lineal(res.x, X_val, Y_val)\n",
    "        Errors[i - 1] = np.array([err, errVal])\n",
    "\n",
    "    plt.plot(sliceSize, Errors[:-1, 0])\n",
    "    plt.plot(sliceSize, Errors[:-1, 1])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def try_funcs():\n",
    "    X, Y, X_val, Y_val, X_test, Y_test = load_data()\n",
    "    m = X.shape[0]\n",
    "    Theta = np.array([1, 1])\n",
    "    X = np.hstack([np.ones([X.shape[0], 1]), X])\n",
    "\n",
    "    print(coste_regularizado(Theta, X, Y, 1))\n",
    "    print(gradiente_regularizado(Theta, X, Y, 1))\n",
    "\n",
    "\n",
    "def polinomize_and_normalize(M, p):\n",
    "    Pol_M = polinomiza_atributos(M, p)\n",
    "    Pol_M, media, varianza = normaliza_matriz(Pol_M)\n",
    "\n",
    "    Pol_M = np.hstack([np.ones([Pol_M.shape[0], 1]), Pol_M])\n",
    "\n",
    "    # TODO puede que haga falta hacer hstack de 1 a la media y 0 a la varianza\n",
    "    # media = np.hstack([np.ones(1), media])\n",
    "    # varianza = np.hstack([np.zeros(1), varianza])\n",
    "\n",
    "    return Pol_M, media, varianza\n",
    "\n",
    "\n",
    "def plot_polynomial_regression(X, Y, Theta, p):\n",
    "    Norm_Pol_X, mu, sigma = polinomize_and_normalize(X, p)\n",
    "    h = Norm_Pol_X.dot(Theta.T)\n",
    "\n",
    "    plotSpace = np.linspace(min(X), max(X), 1700)\n",
    "    plotSpace_np = polinomiza_atributos(plotSpace, p)\n",
    "    plotSpace_np = (plotSpace_np - mu) / sigma\n",
    "    plotSpace_np = np.hstack([np.ones([plotSpace_np.shape[0], 1]), plotSpace_np])\n",
    "\n",
    "    h_plot = plotSpace_np.dot(Theta.T)\n",
    "\n",
    "    plt.scatter(X, Y, marker=\"x\", c='red')\n",
    "    plt.plot(plotSpace, h_plot)  # para dibujar puntos conectados, scatter para puntos suelts\n",
    "\n",
    "\n",
    "def learning_curves_polynomial():\n",
    "    X, Y, X_val, Y_val, X_test, Y_test = load_data()\n",
    "    m = X.shape[0]\n",
    "\n",
    "    p = 8\n",
    "    X_np, media, varianza = polinomize_and_normalize(X, p)\n",
    "    X_val_np, media, varianza = polinomize_and_normalize(X_val, p)\n",
    "\n",
    "    lamb = 0\n",
    "    Errors = np.empty((m, 2))\n",
    "    sliceSize = np.arange(1, m)\n",
    "\n",
    "    for i in sliceSize:\n",
    "        Theta = np.ones(X_np.shape[1])\n",
    "        res = scipy.optimize.minimize(minimize_this_pls, Theta, args=(X_np[0:i], Y[0:i], lamb),\n",
    "                                      jac=True, method='TNC')\n",
    "        err = coste_lineal(res.x, X_np[0:i], Y[0:i])\n",
    "        errVal = coste_lineal(res.x, X_val_np, Y_val)\n",
    "        Errors[i - 1] = np.array([err, errVal])\n",
    "\n",
    "    plot_line(sliceSize, Errors[:-1, 0])\n",
    "    plot_line(sliceSize, Errors[:-1, 1])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def polynomial_regression():\n",
    "    X, Y, X_val, Y_val, X_test, Y_test = load_data()\n",
    "    m = X.shape[0]\n",
    "\n",
    "    p = 8\n",
    "    Pol_X = polinomiza_atributos(X, p)\n",
    "    Norm_Pol_X, media, varianza = normaliza_matriz(Pol_X)\n",
    "\n",
    "    Norm_Pol_X = np.hstack([np.ones([Norm_Pol_X.shape[0], 1]), Norm_Pol_X])\n",
    "    Theta = np.ones(Norm_Pol_X.shape[1])\n",
    "\n",
    "    lamb = 0\n",
    "    res = scipy.optimize.minimize(minimize_this_pls, Theta, args=(Norm_Pol_X, Y, lamb),\n",
    "                                  jac=True, method='TNC')\n",
    "\n",
    "    plot_polynomial_regression(X, Y, res.x, p)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def choose_lambda():\n",
    "    X, Y, X_val, Y_val, X_test, Y_test = load_data()\n",
    "    m = X.shape[0]\n",
    "\n",
    "    p = 8\n",
    "    \n",
    "    X_np, mu, sigma = polinomize_and_normalize(X, p)\n",
    "\n",
    "    X_val_np = polinomiza_atributos(X_val, p)\n",
    "    X_val_np = (X_val_np-mu)/sigma\n",
    "    X_val_np = np.hstack([np.ones([X_val_np.shape[0], 1]), X_val_np])\n",
    "\n",
    "    X_test_np = polinomiza_atributos(X_test, p)\n",
    "    X_test_np = (X_test_np-mu)/sigma\n",
    "    X_test_np = np.hstack([np.ones([X_test_np.shape[0], 1]), X_test_np])\n",
    "\n",
    "    lambdas = np.array([0, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10])\n",
    "    Errors = np.empty((lambdas.shape[0], 2))\n",
    "    i = 0\n",
    "    Theta = np.ones(X_np.shape[1])\n",
    "    \"\"\"for lamb in lambdas:\n",
    "        Theta = np.ones(X_np.shape[1])\n",
    "        res = scipy.optimize.minimize(minimize_this_pls, Theta, args=(X_np, Y, lamb),\n",
    "                                      jac=True, method='TNC')\n",
    "        err = coste_lineal(res.x, X_np, Y)\n",
    "        errVal = coste_lineal(res.x, X_val_np, Y_val)\n",
    "        Errors[i] = np.array([err, errVal])\n",
    "        i = i + 1\n",
    "\n",
    "    plt.plot(lambdas, Errors[:, 0], label='Train')\n",
    "    plt.plot(lambdas, Errors[:, 1], label='Cross Validation')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    res = scipy.optimize.minimize(minimize_this_pls, Theta, args=(X_np, Y, 3),\n",
    "                                  jac=True, method='TNC')\n",
    "    \n",
    "    print(res)\n",
    "    print(coste_lineal(res.x, X_test_np, Y_test))\n",
    "    print(coste_lineal(Theta, X_test_np, Y_test))\n",
    "    print(\"Theta\", Theta)\n",
    "    print(\"newX\", X_np)\n",
    "    print(\"Y\", Y)\"\"\"\n",
    "    print(gradiente_regularizado(Theta, X_np, Y, 3))\n",
    "\n",
    "\n",
    "def main():\n",
    "    # plot_line(X[:, 1:], Y, res.x)\n",
    "    # Errors = learning_curves(X, Y, X_val, Y_val)\n",
    "    #learning_curves()\n",
    "    #polynomial_regression()\n",
    "    choose_lambda()\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e0dd29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c906647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01b80a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
